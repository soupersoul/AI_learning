{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "\n",
    "class Linear(Layer):\n",
    "    def __init__(self, x_dim, units):\n",
    "        super().__init__()\n",
    "        #1\n",
    "        #w_init = tf.random_normal_initializer()\n",
    "        #self.w = tf.Variable(initial_value=w_init(shape=(x_dim, units), dtype=tf.float32), trainable=True)\n",
    "        #2\n",
    "        self.w = self.add_weight(shape=(x_dim, units), initializer='random_normal')\n",
    "        #1\n",
    "        #b_init = tf.zeros_initializer()\n",
    "        #self.b = tf.Variable(initial_value=b_init(shape=(units,), dtype=tf.float32), trainable=True)\n",
    "        #2\n",
    "        self.b = self.add_weight(shape=(units,), initializer=tf.constant_initializer(), trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "print(tf.__version__)\n",
    "linear_layer = Linear(2, 4)\n",
    "y = linear_layer(tf.ones((2, 2)))\n",
    "print(y.shape)\n",
    "assert(linear_layer.weights==[linear_layer.w, linear_layer.b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "\n",
    "class Linear(Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units), initializer=tf.random_normal_initializer(), trainable=True)\n",
    "        self.b = self.add_weight(shape=self.units, initializer=tf.constant_initializer(), trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "linear_layer = Linear(4)\n",
    "y = linear_layer(tf.ones((2, 2)))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([3., 3.], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([7., 7.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "\n",
    "class ComputeSum(Layer):\n",
    "    def __init__(self, x_dim):\n",
    "        super().__init__()\n",
    "        self.total = tf.Variable(initial_value=tf.zeros(shape=(x_dim,)), trainable=False)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        self.total.assign_add(tf.reduce_sum(inputs, axis=0))\n",
    "        return self.total\n",
    "    \n",
    "sum = ComputeSum(2)\n",
    "y = sum(tf.ones((3,2)))\n",
    "print(y)\n",
    "y2 = sum(tf.ones((4,2)))\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 10)\n"
     ]
    }
   ],
   "source": [
    "class MLP(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = Linear(32)\n",
    "        self.linear_2 = Linear(32)\n",
    "        self.linear_3 = Linear(10)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.linear_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.linear_2(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.linear_3(inputs)\n",
    "        return x\n",
    "    \n",
    "mlp = MLP()\n",
    "y = mlp(tf.ones((3, 64)))\n",
    "print(y.shape)\n",
    "assert len(mlp.weights)==6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(Layer):\n",
    "    def __init__(self, rate):\n",
    "        super().__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs, training = None):\n",
    "        if training:\n",
    "            return tf.nn.dropout(inputs, rate = self.rate)\n",
    "        return inputs\n",
    "    \n",
    "class MLPWithDropout(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = Linear(32)\n",
    "        self.dropout = Dropout(0.5)\n",
    "        self.linear_2 = Linear(10)\n",
    "        \n",
    "    def call(self, inputs, training = None):\n",
    "        x = self.linear_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        self.dropout(x, training = training)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "    \n",
    "mlp = MLPWithDropout()\n",
    "y_train = mlp(tf.ones((2,2)), training = True)\n",
    "y_test = mlp(tf.ones((2, 2)), training = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(2, 10)\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(16,))\n",
    "x = Linear(32)(inputs)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs= Linear(10)(x)\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "y = model(tf.ones((2, 16)))\n",
    "print(len(model.weights))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "model = Sequential([\n",
    "    Linear(32), Dropout(0.5), Linear(10)\n",
    "])\n",
    "y = model(tf.ones((2, 16)))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.379094\n"
     ]
    }
   ],
   "source": [
    "bce = tf.keras.losses.BinaryCrossentropy()\n",
    "y_true = [0., 0, 1., 1]\n",
    "y_pred = [1., 1, 0., 0]\n",
    "loss = bce(y_true, y_pred)\n",
    "print(loss.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp result: 0.6666667\n",
      "final result: 0.71428573\n"
     ]
    }
   ],
   "source": [
    "m = tf.keras.metrics.AUC()\n",
    "m.update_state([0, 1, 1, 1],[0, 1, 0, 0])\n",
    "print(\"temp result:\", m.result().numpy())\n",
    "m.update_state([1, 1, 1, 1], [0, 1, 1, 0])\n",
    "print(\"final result:\", m.result().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp result: 1.0\n",
      "final result: 3.0\n"
     ]
    }
   ],
   "source": [
    "class BinaryTruePositives(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name=\"binary_true_positives\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name='cp', initializer = tf.zeros_initializer())\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight = None):\n",
    "        y_true = tf.cast(y_true, tf.bool)\n",
    "        y_pred = tf.cast(y_pred, tf.bool)\n",
    "        values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))\n",
    "        values = tf.cast(values, self.dtype)\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.cast(sample_weight, self.dtype)\n",
    "            sample_weight = tf.broadcast_weights(sample_weight, values)\n",
    "            values = tf.multiple(sample_weight, values)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(values))\n",
    "        \n",
    "    def result(self):\n",
    "        return self.true_positives\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0)\n",
    "        \n",
    "btp = BinaryTruePositives()\n",
    "btp.update_state([0, 1, 1, 1], [0, 1, 0, 0])\n",
    "print(\"temp result:\", btp.result().numpy())\n",
    "btp.update_state([1, 1, 1, 1], [0, 1, 1, 0])\n",
    "print(\"final result:\", btp.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0\n",
      "Loss from lass step:2.397\n",
      "Total runing accuracy so far:0.109\n",
      "step: 100\n",
      "Loss from lass step:0.179\n",
      "Total runing accuracy so far:0.826\n",
      "step: 200\n",
      "Loss from lass step:0.551\n",
      "Total runing accuracy so far:0.869\n",
      "step: 300\n",
      "Loss from lass step:0.200\n",
      "Total runing accuracy so far:0.890\n",
      "step: 400\n",
      "Loss from lass step:0.220\n",
      "Total runing accuracy so far:0.904\n",
      "step: 500\n",
      "Loss from lass step:0.352\n",
      "Total runing accuracy so far:0.912\n",
      "step: 600\n",
      "Loss from lass step:0.192\n",
      "Total runing accuracy so far:0.919\n",
      "step: 700\n",
      "Loss from lass step:0.169\n",
      "Total runing accuracy so far:0.924\n",
      "step: 800\n",
      "Loss from lass step:0.144\n",
      "Total runing accuracy so far:0.927\n",
      "step: 900\n",
      "Loss from lass step:0.115\n",
      "Total runing accuracy so far:0.931\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train[:].reshape(60000, 784).astype('float32') / 255\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "dataset = dataset.shuffle(buffer_size=256).batch(64)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "for step, (x, y) in enumerate(dataset):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x)\n",
    "        loss_value = loss(y, logits)\n",
    "    gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    accuracy.update_state(y, logits)\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(\"step:\",step)\n",
    "        print(\"Loss from lass step:%.3f\" %(loss_value,))\n",
    "        print(\"Total runing accuracy so far:%.3f\" %(accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "x_test = x_test[:].reshape(10000, 784).astype('float32') / 255\n",
    "test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_data = test_data.batch(128)\n",
    "accuracy.reset_states()\n",
    "for step, (x_t, y_t) in enumerate(test_data):\n",
    "    tlogits = model(x_t)\n",
    "    accuracy.update_state(y,logits)\n",
    "print(\"Final test accuracy: %.3f\" %accuracy.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot update variable with shape [2] using a Tensor with shape [], shapes must be equal. [Op:AssignAddVariableOp]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-2f9ebebc22ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# 加上正则化损失\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;31m# 求梯度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-4271bbae29d1>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign_add\u001b[0;34m(self, delta, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    779\u001b[0m       assign_add_op = gen_resource_variable_ops.assign_add_variable_op(\n\u001b[1;32m    780\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    782\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_add_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_add_variable_op\u001b[0;34m(resource, value, name)\u001b[0m\n\u001b[1;32m     63\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot update variable with shape [2] using a Tensor with shape [], shapes must be equal. [Op:AssignAddVariableOp]"
     ]
    }
   ],
   "source": [
    "\n",
    "class ActivityRegularization(Layer):\n",
    "    \"\"\"计算l2 regularization\"\"\"\n",
    "    def __init__(self,rate=1e-2):\n",
    "        super().__init__()\n",
    "        self.rate=rate\n",
    "    def call(self,inputs):\n",
    "        \"\"\"根据输入，使用`add_loss`来添加regularization loss\"\"\"\n",
    "        self.add_loss(self.rate*tf.reduce_sum(tf.square(inputs)))\n",
    "        return inputs\n",
    "\n",
    "class SparseMLP(Layer):\n",
    "    \"\"\"堆叠多个linear layer,并且加正则化\"\"\"\n",
    "    def __init__(self,output_dim):\n",
    "        super().__init__()\n",
    "        self.dense_1 = layers.Dense(32,activation=tf.nn.relu)\n",
    "        self.regularization= ActivityRegularization(1e-2)\n",
    "        self.dense_2 = layers.Dense(output_dim)\n",
    "    def call(self,inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = self.regularization(x)\n",
    "        x = self.dense_2(x)\n",
    "        return x\n",
    "\n",
    "(x_train,y_train),_=tf.keras.datasets.mnist.load_data()\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train[:].reshape(60000,784).astype('float32')/255,y_train))\n",
    "\n",
    "dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "(x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train.reshape(60000, 784).astype('float32') / 255, y_train))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# 定义一个新的MLP\n",
    "mlp = SparseMLP(10)\n",
    "\n",
    "#losses and optimizer\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "for step,(x,y) in enumerate(dataset):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 前向运算\n",
    "        logits = mlp(x)\n",
    "        # 求前向运算损失\n",
    "        loss = loss_fn(y,logits)\n",
    "        # 加上正则化损失\n",
    "        loss = loss + sum(mlp.losses)\n",
    "        # 求梯度\n",
    "        gradients = tape.gradient(loss,mlp.trainable_weights)\n",
    "    #更新参数\n",
    "    optimizer.apply_gradients(zip(gradients,mlp.trainable_weights))\n",
    "    #日志\n",
    "    if step %100==0:\n",
    "        print(\"Loss at step %d: %.3f\" %(step,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
