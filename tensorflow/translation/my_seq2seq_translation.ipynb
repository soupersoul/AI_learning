{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. preprocessing data\n",
    "# 2. build model\n",
    "# 2.1 encoder\n",
    "# 2.2 attention\n",
    "# 2.3 decoder\n",
    "# 2.4 loss & optimizer\n",
    "# 2.5 train\n",
    "# 3. evaluation\n",
    "# 3.1 given sentence ,return translated results\n",
    "# 3.2 visualize results (attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo .  si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
     ]
    }
   ],
   "source": [
    "en_spa_file_path = './spa-eng/spa.txt'\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "def unicode2ascii(seq):\n",
    "    return \"\".join(c for c in unicodedata.normalize('NFD', seq) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "import re\n",
    "def preprocess_sequence(seq):\n",
    "    seq = unicode2ascii(seq.lower().strip())\n",
    "    seq = re.sub(r\"([?¿:,.!])\", r\" \\1 \", seq)\n",
    "    seq = re.sub(\" +\", \" \", seq)\n",
    "    seq = re.sub(r'[^a-zA-Z?.!,¿]', \" \", seq)\n",
    "    seq = seq.rstrip().strip()\n",
    "    seq = \"<start> \" + seq + \" <end>\"\n",
    "    return seq\n",
    "\n",
    "t='If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\tSi quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.'\n",
    "print(preprocess_sequence(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
      "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
     ]
    }
   ],
   "source": [
    "lines = open(en_spa_file_path, encoding=\"UTF-8\").read().strip().split('\\n')\n",
    "seq_pairs = [line.split('\\t') for line in lines]\n",
    "en_spa_pairs = [(preprocess_sequence(en), preprocess_sequence(spa)) for (en, spa) in seq_pairs]\n",
    "en_dataset, sp_dataset = zip(*en_spa_pairs)\n",
    "print(en_dataset[-1])\n",
    "print(sp_dataset[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 16)\n",
      "(64, 11)\n"
     ]
    }
   ],
   "source": [
    "def tokenizer(lang_dataset):\n",
    "    toker = keras.preprocessing.text.Tokenizer(num_words=None, filters='', split=' ')\n",
    "    toker.fit_on_texts(lang_dataset)\n",
    "    tensor = toker.texts_to_sequences(lang_dataset)\n",
    "    tensor = keras.preprocessing.sequence.pad_sequences(tensor)\n",
    "    return tensor, toker\n",
    "\n",
    "output_tensor, output_tokenizer = tokenizer(en_dataset[0:30000])\n",
    "input_tensor, input_tokenizer = tokenizer(sp_dataset[0:30000])\n",
    "\n",
    "def max_length(tensor):\n",
    "    return max(len(i) for i in tensor)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_eval, output_train, output_eval = train_test_split(input_tensor, output_tensor, test_size=0.2)\n",
    "\n",
    "max_length_input = max_length(input_tensor)\n",
    "max_length_output = max_length(output_tensor)\n",
    "buffer_size = 30000\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "def make_tf_dataset(input_tensor, output_tensor, batch_size, epochs, shuffle):\n",
    "    tf_dataset = tf.data.Dataset.from_tensor_slices((input_tensor, output_tensor))\n",
    "    if shuffle:\n",
    "        tf_dataset = tf_dataset.shuffle(buffer_size)\n",
    "    return tf_dataset.repeat(epochs).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "train_set = make_tf_dataset(input_train, output_train, batch_size, epochs, True)\n",
    "eval_set = make_tf_dataset(input_eval, output_eval, batch_size, 1, False)\n",
    "\n",
    "for x, y in train_set.take(1):\n",
    "    print(x.shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_units = 256\n",
    "units = 1024\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "output_vocab_size = len(output_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.rnn_units = rnn_units\n",
    "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = keras.layers.GRU(rnn_units, return_state=True, return_sequences=True, recurrent_initializer=\"glorot_uniform\")\n",
    "        \n",
    "    def call(self, x, hidden_state):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden_state)\n",
    "        return output, state\n",
    "    \n",
    "    def initial_state(self):\n",
    "        return tf.zeros((batch_size, self.rnn_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.W1 = keras.layers.Dense(units)\n",
    "        self.W2 = keras.layers.Dense(units)\n",
    "        self.V = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, hidden_state, encoder_output):\n",
    "        hidden = tf.expand_dims(hidden_state, axis=1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(hidden) + self.W2(encoder_output)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context = tf.reduce_sum(attention_weights*encoder_output, axis=1)\n",
    "        return context, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.fc = keras.layers.Dense(vocab_size)\n",
    "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn_units = rnn_units\n",
    "        self.gru = keras.layers.GRU(rnn_units, return_sequences=True, return_state=True, recurrent_initializer=\"glorot_uniform\")\n",
    "        self.attention = BahdanauAttention(self.rnn_units)\n",
    "        \n",
    "    def call(self, x, hidden_state, encoder_output):\n",
    "        # context.shape: (batch_size, units)\n",
    "        context, attention_weights = self.attention(hidden_state, encoder_output)\n",
    "        # batch_size, 1, embedding_dim\n",
    "        x = self.embedding(x)\n",
    "        combine_x = tf.concat([tf.expand_dims(context, axis=1), x], axis=-1)\n",
    "        # output: batch_size, 1, rnn_units\n",
    "        # state:  batch_size, rnn_units\n",
    "        output, state = self.gru(combine_x)\n",
    "        #output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        output = tf.squeeze(output, 1)\n",
    "        output = self.fc(output)\n",
    "        return output, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([3. 3.], shape=(2,), dtype=float32)\n",
      "(2, 1, 3)\n",
      "3\n",
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 3.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 3.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor([ True  True False  True False  True], shape=(6,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "t = tf.constant([[[1., 2., 3.]], [[4., 5., 3.]]])\n",
    "v=tf.reshape(t, (-1, t.shape[2]))\n",
    "print(v[:,2])\n",
    "print(t.shape)\n",
    "print(t.shape[2])\n",
    "print(tf.reshape(t, (-1, t.shape[2])))\n",
    "print(tf.squeeze(t, 1))\n",
    "a = tf.constant([1,2,0,3,0,5])\n",
    "print(tf.not_equal(a, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "loss_object = keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_func(real, pred):\n",
    "    mask = tf.not_equal(real, 0)\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_vocab_size, embedding_units, units, batch_size)\n",
    "decoder = Decoder(output_vocab_size, embedding_units, units, batch_size)\n",
    "\n",
    "@tf.function\n",
    "def train_step(input, target, hidden):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        encode_output, hidden = encoder(input, hidden)\n",
    "        for t in range(target.shape[1] - 1):\n",
    "            decode_input = tf.expand_dims(target[:, t], axis=-1)\n",
    "            pred, hidden_state, _ = decoder(decode_input, hidden, encode_output)\n",
    "            loss += loss_func(target[:, t+1], pred)\n",
    "    batch_loss = loss / int(target.shape[0])\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.2992\n",
      "Epoch 1 Batch 100 Loss 0.3037\n",
      "Epoch 1 Batch 200 Loss 0.2985\n",
      "Epoch 1 Batch 300 Loss 0.2725\n",
      "Epoch 1 Batch 400 Loss 0.2706\n",
      "Epoch 1 Loss 0.2960\n",
      "Time take for 1 epoch 1258.712735414505 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.2683\n",
      "Epoch 2 Batch 100 Loss 0.2761\n",
      "Epoch 2 Batch 200 Loss 0.2608\n",
      "Epoch 2 Batch 300 Loss 0.2459\n",
      "Epoch 2 Batch 400 Loss 0.2504\n",
      "Epoch 2 Loss 0.2635\n",
      "Time take for 1 epoch 1202.2063212394714 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.2356\n",
      "Epoch 3 Batch 100 Loss 0.2421\n",
      "Epoch 3 Batch 200 Loss 0.2439\n",
      "Epoch 3 Batch 300 Loss 0.2325\n",
      "Epoch 3 Batch 400 Loss 0.2265\n",
      "Epoch 3 Loss 0.2410\n",
      "Time take for 1 epoch 1436.0191569328308 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.2411\n",
      "Epoch 4 Batch 100 Loss 0.2178\n",
      "Epoch 4 Batch 200 Loss 0.2337\n",
      "Epoch 4 Batch 300 Loss 0.2244\n",
      "Epoch 4 Batch 400 Loss 0.2196\n",
      "Epoch 4 Loss 0.2232\n",
      "Time take for 1 epoch 1165.0504508018494 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.2106\n",
      "Epoch 5 Batch 100 Loss 0.2217\n",
      "Epoch 5 Batch 200 Loss 0.1993\n",
      "Epoch 5 Batch 300 Loss 0.2147\n",
      "Epoch 5 Batch 400 Loss 0.1975\n",
      "Epoch 5 Loss 0.2073\n",
      "Time take for 1 epoch 1174.7853741645813 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.2091\n",
      "Epoch 6 Batch 100 Loss 0.1947\n",
      "Epoch 6 Batch 200 Loss 0.1885\n",
      "Epoch 6 Batch 300 Loss 0.2011\n",
      "Epoch 6 Batch 400 Loss 0.1757\n",
      "Epoch 6 Loss 0.1858\n",
      "Time take for 1 epoch 1166.0905783176422 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1602\n",
      "Epoch 7 Batch 100 Loss 0.1522\n",
      "Epoch 7 Batch 200 Loss 0.1529\n",
      "Epoch 7 Batch 300 Loss 0.1741\n",
      "Epoch 7 Batch 400 Loss 0.1453\n",
      "Epoch 7 Loss 0.1565\n",
      "Time take for 1 epoch 1170.0171573162079 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1278\n",
      "Epoch 8 Batch 100 Loss 0.1362\n",
      "Epoch 8 Batch 200 Loss 0.1370\n",
      "Epoch 8 Batch 300 Loss 0.1148\n",
      "Epoch 8 Batch 400 Loss 0.1010\n",
      "Epoch 8 Loss 0.1227\n",
      "Time take for 1 epoch 1166.3916311264038 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0961\n",
      "Epoch 9 Batch 100 Loss 0.0932\n",
      "Epoch 9 Batch 200 Loss 0.0810\n",
      "Epoch 9 Batch 300 Loss 0.0824\n",
      "Epoch 9 Batch 400 Loss 0.0626\n",
      "Epoch 9 Loss 0.0891\n",
      "Time take for 1 epoch 1165.7284071445465 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0531\n",
      "Epoch 10 Batch 100 Loss 0.0650\n",
      "Epoch 10 Batch 200 Loss 0.0655\n",
      "Epoch 10 Batch 300 Loss 0.0695\n",
      "Epoch 10 Batch 400 Loss 0.0400\n",
      "Epoch 10 Loss 0.0607\n",
      "Time take for 1 epoch 1163.7869474887848 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = len(input_tensor) // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    time_start = time.time()\n",
    "    total_loss = 0\n",
    "    hidden = encoder.initial_state()\n",
    "    \n",
    "    for (batch, (input, targ)) in enumerate(train_set.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(input, targ, hidden)\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
    "            \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch+1, total_loss / steps_per_epoch))\n",
    "    \n",
    "    print('Time take for 1 epoch {} sec\\n'.format(time.time() - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
