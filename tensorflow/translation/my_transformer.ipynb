{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "sys.version_info(major=3, minor=7, micro=4, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.3\n",
      "numpy 1.18.1\n",
      "pandas 1.0.1\n",
      "sklearn 0.22.1\n",
      "tensorflow 2.1.0\n",
      "tensorflow_core.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "examples, info = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)\n",
    "train_data, val_data = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_data), target_vocab_size = 2 ** 13 \n",
    ")\n",
    "\n",
    "en_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_data), target_vocab_size = 2 ** 13 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 20000\n",
    "batch_size = 64\n",
    "max_length = 40\n",
    "\n",
    "def encode_to_subword(pt_sentence, en_sentence):\n",
    "    pt_sequence = [pt_tokenizer.vocab_size] + pt_tokenizer.encode(pt_sentence.numpy()) + [pt_tokenizer.vocab_size + 1]\n",
    "    en_sequence = [en_tokenizer.vocab_size] + en_tokenizer.encode(en_sentence.numpy()) + [en_tokenizer.vocab_size + 1]\n",
    "    return pt_sequence, en_sequence\n",
    "\n",
    "#def encode_to_subword(pt_sentence, en_sentence):\n",
    "# <start> sentence<end>\n",
    "#    pt_sequence = [pt_tokenizer.vocab_size] + pt_tokenizer.encode(pt_sentence.numpy()) + [pt_tokenizer.vocab_size + 1]\n",
    "#    en_sequence = [en_tokenizer.vocab_size] + en_tokenizer.encode(en_sentence.numpy()) + [en_tokenizer.vocab_size + 1]\n",
    "#    return pt_sequence, en_sequence\n",
    "\n",
    "def filter_by_max_length(pt_sequence, en_sequence):\n",
    "    return tf.logical_and(tf.size(pt_sequence) < max_length, tf.size(en_sequence) < max_length)\n",
    "\n",
    "def tf_func_encode_to_subword(pt_sentence, en_sentence):\n",
    "    return tf.py_function(encode_to_subword, [pt_sentence, en_sentence], [tf.int64, tf.int64])\n",
    "\n",
    "#train_dataset = train_data.map(tf_func_encode_to_subword)\n",
    "#train_dataset = train_dataset.filter(filter_by_max_length)\n",
    "# [-1], [-1]表示当前函数有两个维度，每个维度都在当前维度扩展到最大值\n",
    "#train_dataset.shuffle(buffer_size).padded_batch(batch_size, padded_shapes=([-1], [-1]))\n",
    "\n",
    "train_dataset = train_data.map(tf_func_encode_to_subword).filter(filter_by_max_length).shuffle(buffer_size).padded_batch(batch_size, padded_shapes=([-1], [-1]))\n",
    "val_dataset = val_data.map(tf_func_encode_to_subword).filter(filter_by_max_length).shuffle(buffer_size).padded_batch(batch_size, padded_shapes=([-1], [-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 37) (64, 39)\n",
      "(64, 37) (64, 38)\n",
      "(64, 39) (64, 39)\n",
      "(64, 38) (64, 37)\n",
      "(64, 38) (64, 38)\n"
     ]
    }
   ],
   "source": [
    "for pt_batch, en_batch in train_dataset.take(5):\n",
    "    print(pt_batch.shape, en_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 40, 512)\n"
     ]
    }
   ],
   "source": [
    "# PE(pos, 2i) = sin(pos /10000^(2i/d_model))\n",
    "# PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
    "\n",
    "# pos.shape: [sentence_length, 1]\n",
    "# i.shape: [1, d_model]\n",
    "# result.shape: [sentence_length, d_model]\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i / 2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "                               \n",
    "def get_position_embedding(sequence_length, d_model):\n",
    "    angles = get_angles(np.arange(sequence_length)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n",
    "    sines = np.sin(angles[:, 0::2])\n",
    "    cosines = np.cos(angles[:, 1::2])\n",
    "    position_embedding = np.concatenate([sines, cosines], axis=-1)\n",
    "    position_embedding = position_embedding[np.newaxis, :]   # 为了后续使用方便\n",
    "    return tf.cast(position_embedding, dtype=tf.float32)\n",
    "\n",
    "position_embedding = get_position_embedding(40, 512)\n",
    "print(position_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[0., 1., 1., 1., 1.],\n",
       "       [0., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_data.shape: [batch_size, seq_len]\n",
    "def create_padding_mask(batch_data):\n",
    "    print(batch_data.shape)\n",
    "    mask = tf.cast(tf.math.equal(batch_data, 0), tf.float32)\n",
    "    # [batch_size, 1, 1, seq_len]\n",
    "    return mask[:, np.newaxis, np.newaxis, :]\n",
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "create_look_ahead_mask(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    # q.shape: (..., seq_len_q, depth)\n",
    "    # k.shape: (..., seq_len, depth)\n",
    "    # v.shape: (..., seq_len, depth_v)\n",
    "    \n",
    "    # matmul_qk.shape: (batch_size, seq_len_q, seq_len)\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "    dk = tf.cast(k.shape[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += mask * (-1e9)\n",
    "    \n",
    "    # shape: (..., seq_len_q, seq_len)\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "    # shape: (..., seq_len_q, depth_v)\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights\n",
    "    \n",
    "def print_scaled_dot_product_attention(q, k, v):\n",
    "    temp_out, temp_att = scaled_dot_product_attention(q, k, v, None)\n",
    "    print(\"Attention weights are:\")\n",
    "    print(temp_att)\n",
    "    print(\"Output is:\")\n",
    "    print(temp_out)\n",
    "    \n",
    "temp_k = tf.constant([[10, 0, 0], \n",
    "                                   [0, 10, 0],\n",
    "                                   [0, 0, 10],\n",
    "                                   [0, 0, 10]], dtype=tf.float32)  # (4, 3)\n",
    "temp_v = tf.constant([[10, 0], [10, 0], [100, 5], [1000, 6]], dtype=tf.float32) # (4, 2)\n",
    "\n",
    "temp_q1 = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "np.set_printoptions(suppress=True)\n",
    "print_scaled_dot_product_attention(temp_q1, temp_k, temp_v)\n",
    "# q * k -> 只有[0, 10, 0]行的结果非0, 所以是　[0, 1, 0, 0]\n",
    "# q * k * v -> [0, 1, 0, 0]与v相乘只有第二行有结果, 即[10, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 60, 512)\n",
      "(1, 8, 60, 60)\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert d_model % num_heads == 0\n",
    "        self.depth = d_model // num_heads\n",
    "        self.WQ = keras.layers.Dense(d_model)\n",
    "        self.WK = keras.layers.Dense(d_model)\n",
    "        self.WV = keras.layers.Dense(d_model)\n",
    "        self.dense = keras.layers.Dense(d_model)\n",
    "\n",
    "    def reshape_heads(self, x, batch_size):\n",
    "        # x.shape: (batch_size, seq_len, d_model)\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, q, k, v, mask):\n",
    "        batch_size = q.shape[0]\n",
    "        q = self.reshape_heads(self.WQ(q), batch_size)\n",
    "        k = self.reshape_heads(self.WK(k), batch_size)\n",
    "        v = self.reshape_heads(self.WQ(v), batch_size)\n",
    "        \n",
    "        scaled_attention_output, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "        # scaled_attention_output.shape: (batch_size, num_heads, seq_len, depth)\n",
    "        \n",
    "        # shape: (batch_size, seq_len, d_model)\n",
    "        scaled_attention_outputs = tf.reshape(tf.transpose(scaled_attention_output, [0, 2, 1, 3]),\n",
    "                                                                  (batch_size, -1, self.d_model))\n",
    "        return self.dense(scaled_attention_outputs), attention_weights\n",
    "        \n",
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8) # dk = 64\n",
    "y = tf.random.uniform((1, 60, 256)) #(batch_size, seq_len_q, dim)\n",
    "output, attn = temp_mha(y, y, y, mask=None)\n",
    "print(output.shape)\n",
    "print(attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feed_forward_network(d_model, dff):\n",
    "    return keras.models.Sequential([\n",
    "        keras.layers.Dense(dff, activation='relu'),\n",
    "        keras.layers.Dense(d_model)\n",
    "    ])\n",
    "\n",
    "sample_ffn = feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 50, 512)\n"
     ]
    }
   ],
   "source": [
    "class EncoderLayer(keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = feed_forward_network(d_model, dff)\n",
    "        self.norm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.drop1 = keras.layers.Dropout(rate)\n",
    "        self.norm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.drop2 = keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, is_training, mask):\n",
    "        # shape: (batch_size, seq_len, d_model)\n",
    "        attention_out, _ = self.mha(x, x, x, mask)\n",
    "        attention_out = self.drop1(attention_out, training=is_training)\n",
    "        out1 = self.norm1(x + attention_out)\n",
    "        \n",
    "        ffn_out = self.ffn(out1)\n",
    "        ffn_out = self.drop2(ffn_out, training=is_training)\n",
    "        out2 = self.norm2(out1 + ffn_out)\n",
    "        return out2\n",
    "    \n",
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "sampe_input = tf.random.uniform((64, 50, 512))\n",
    "sample_output = sample_encoder_layer(sampe_input, False, None)\n",
    "print(sample_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 60, 512)\n",
      "(64, 8, 60, 60)\n",
      "(64, 8, 60, 50)\n"
     ]
    }
   ],
   "source": [
    "class DecoderLayer(keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "        \n",
    "        self.ffn = feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.norm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm3 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.drop1 = keras.layers.Dropout(rate)\n",
    "        self.drop2 = keras.layers.Dropout(rate)\n",
    "        self.drop3 = keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, encoder_outputs, is_training, look_ahead_mask, padding_mask):\n",
    "        # shape: (batch_size, seq_len, d_model)\n",
    "        atten_out1, atten_weight1 = self.mha1(x, x, x, look_ahead_mask)\n",
    "        atten_out1 = self.drop1(atten_out1, training=is_training)\n",
    "        out1 = self.norm1(x + atten_out1)\n",
    "        \n",
    "        atten_out2, atten_weight2 = self.mha2(x, encoder_outputs, encoder_outputs, padding_mask)\n",
    "        atten_out2 = self.drop2(atten_out2, training=is_training)\n",
    "        out2 = self.norm2(out1 + atten_out2)\n",
    "        \n",
    "        ffn_out = self.ffn(out2)\n",
    "        ffn_out = self.drop3(ffn_out, training=is_training)\n",
    "        out3 = self.norm3(ffn_out + out2)\n",
    "        return out3, atten_weight1, atten_weight2\n",
    "    \n",
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "sample_decoder_input = tf.random.uniform((64, 60, 512))\n",
    "sample_decoder_output, sample_decoder_attn_weights1, sample_deocder_attn_weights2 = sample_decoder_layer(sample_decoder_input, sample_output, False, None, None)\n",
    "\n",
    "print(sample_decoder_output.shape)\n",
    "print(sample_decoder_attn_weights1.shape)\n",
    "print(sample_deocder_attn_weights2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 37, 512)\n"
     ]
    }
   ],
   "source": [
    "class EncoderModel(keras.layers.Layer):\n",
    "    def __init__(self, num_layers, input_vocab_size, max_length, d_model, num_heads, dff, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.d_model = d_model\n",
    "        self.max_length = max_length\n",
    "        self.embedding = keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.position_embedding = get_position_embedding(max_length, d_model)\n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        self.encoder_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        \n",
    "    def call(self, x, is_training, mask):\n",
    "        # x.shape: (batch_size, input_seq_len)\n",
    "        input_seq_len = x.shape[1]\n",
    "        tf.debugging.assert_less_equal(input_seq_len, self.max_length, \"input_seq_len should be less or equal to self.max_length\")\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.position_embedding[:, :input_seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x, training=is_training)\n",
    "        for i in range(self.num_layers):\n",
    "            encoder_layer = self.encoder_layers[i]\n",
    "            x = encoder_layer(x, is_training, mask)\n",
    "        return x\n",
    "    \n",
    "sample_encoder_model = EncoderModel(2, 8500, max_length, 512, 8, 2048)\n",
    "sample_encoder_model_input = tf.random.uniform((64, 37))\n",
    "sample_encoder_model_output = sample_encoder_model(sample_encoder_model_input, False, mask=None)\n",
    "\n",
    "print(sample_encoder_model_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 35, 512)\n",
      "(64, 37, 512)\n",
      "(64, 8, 35, 35)\n",
      "(64, 8, 35, 37)\n",
      "(64, 8, 35, 35)\n",
      "(64, 8, 35, 37)\n"
     ]
    }
   ],
   "source": [
    "class DecoderModel(keras.layers.Layer):\n",
    "    def __init__(self, num_layers, target_vocab_size, max_length, d_model, num_heads, dff, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.d_model = d_model\n",
    "        self.max_length = max_length\n",
    "        self.embedding = keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.position_embedding = get_position_embedding(max_length, d_model)\n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        self.decoder_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        \n",
    "    def call(self, x, encoding_outputs, training, look_ahead_mask, padding_mask):\n",
    "        out_seq_len = tf.shape(x)[1]\n",
    "        tf.debugging.assert_less_equal(out_seq_len, self.max_length, \"output_seq_len should be less or equal to self.max_length\")\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        pos_embedding = self.position_embedding[:, :out_seq_len, :]\n",
    "        print(pos_embedding.shape)\n",
    "        x += pos_embedding\n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        attention_weights = {}\n",
    "        for i in range(self.num_layers):\n",
    "            x, attn1, attn2 = self.decoder_layers[i](x, encoding_outputs, training, look_ahead_mask, padding_mask)\n",
    "            attention_weights['decoder_layer{}_att1'.format(i+1)] = attn1\n",
    "            attention_weights['decoder_layer{}_att2'.format(i+1)] = attn2\n",
    "        return x, attention_weights\n",
    "    \n",
    "sample_decoder_model = DecoderModel(2, 8000, max_length, 512, 8, 2048)\n",
    "sample_decoder_model_input = tf.random.uniform((64, 35))\n",
    "sample_decoder_model_output, sample_decoder_model_att = sample_decoder_model(sample_decoder_model_input, sample_encoder_model_output, training=False, look_ahead_mask=None, padding_mask=None)\n",
    "print(sample_encoder_model_output.shape)\n",
    "for key in sample_decoder_model_att:\n",
    "    print(sample_decoder_model_att[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 31, 512)\n",
      "(1, 31, 512)\n",
      "(64, 31, 8000)\n",
      "decoder_layer1_att1 (64, 8, 31, 31)\n",
      "decoder_layer1_att2 (64, 8, 31, 26)\n",
      "decoder_layer2_att1 (64, 8, 31, 31)\n",
      "decoder_layer2_att2 (64, 8, 31, 26)\n"
     ]
    }
   ],
   "source": [
    "class TransformerModel(keras.models.Model):\n",
    "    def __init__(self, num_layers, input_vocab_size, target_vocab_size, max_length, d_model, num_heads, dff, rate):\n",
    "        super().__init__()\n",
    "        self.encoder_model = EncoderModel(num_layers, input_vocab_size, max_length, d_model, num_heads, dff, rate)\n",
    "        self.decoder_model = DecoderModel(num_layers, target_vocab_size, max_length, d_model, num_heads, dff, rate)\n",
    "        self.final_layer = keras.layers.Dense(target_vocab_size)\n",
    "        \n",
    "    def call(self, inp, tar, training, encoder_padding_mask, look_ahead_mask, decoder_padding_mask):\n",
    "        encoder_output = self.encoder_model(inp, training, encoder_padding_mask)\n",
    "        decoder_output, attention_weights = self.decoder_model(tar, encoder_output, training, look_ahead_mask, decoder_padding_mask)\n",
    "        prediction = self.final_layer(decoder_output)\n",
    "        return prediction, attention_weights\n",
    "\n",
    "sample_transformer = TransformerModel(2, 8500, 8000, 40, 512, 8, 2048, 0.1)\n",
    "temp_input = tf.random.uniform((64, 26))\n",
    "temp_target = tf.random.uniform((64, 31))\n",
    "\n",
    "predictions, attention_weights = sample_transformer(temp_input, temp_target, training=False, encoder_padding_mask=None, look_ahead_mask=None, decoder_padding_mask =None)\n",
    "print(predictions.shape)\n",
    "for key in attention_weights:\n",
    "    print(key, attention_weights[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. initialize model\n",
    "# 2. define loss, optimizer, learning_rate schedule\n",
    "# 3. train_step\n",
    "# 4. train process\n",
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "input_vocab_size = pt_tokenizer.vocab_size + 2\n",
    "target_vocab_size = en_tokenizer.vocab_size + 2\n",
    "dropout_rate = 0.1\n",
    "transformer = Transformer(num_layers, input_vocab_size, target_vocab_size, max_length, d_model, num_heads, dff, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate调整策略\n",
    "# lrate = (d_model ** -0.5) * min(step_num ** (-0.5), step_num * warm_up_steps ** (-1.5))\n",
    "\n",
    "class CustomizedSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super().__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "        \n",
    "    def __call__(self, step_num):\n",
    "        arg1 = tf.math.rsqrt(self.d_model)\n",
    "        arg2 = tf.math.rsqrt(step_num)\n",
    "        arg3 = step_num * (self.warmup_steps ** (-1.5))\n",
    "        return arg1 * tf.math.minimum(arg2, arg3)\n",
    "    \n",
    "learning_rate = CustomizedSchedule(d_model)\n",
    "optimizer = keras.optimizers.Adam(learning_rate, beta_1 = 0.9, beta_2=0.98, epsilon=1e-9)\n",
    "temp_learning_rate_schedule = CustomizedSchedule(d_model)\n",
    "#plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "#plt.ylabel(\"Learning rate\")\n",
    "#plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_func(real, pred):\n",
    "    mask = tf.math.not_equal(real, 0)\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 36)\n",
      "(64, 36)\n",
      "(64, 36)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 1, 1, 36), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 1, 36, 36), dtype=float32, numpy=\n",
       " array([[[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 1, 1, 36), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_masks(inp, tar):\n",
    "    encoder_padding_mask = create_padding_mask(inp)\n",
    "    encoder_decoder_padding_mask = create_padding_mask(inp)\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    decoder_padding_mask = create_padding_mask(tar)\n",
    "    \n",
    "    decoder_mask = tf.maximum(look_ahead_mask, decoder_padding_mask)\n",
    "    return encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask\n",
    "\n",
    "temp_inp, temp_tar = iter(train_dataset.take(1)).next()\n",
    "create_masks(temp_inp, temp_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 34)\n",
      "(64, 34)\n",
      "(64, 34)\n",
      "(64, 34, 128)\n",
      "(1, 34, 128)\n",
      "(64, 34)\n",
      "(64, 34)\n",
      "(64, 34)\n",
      "(64, 34, 128)\n",
      "(1, 34, 128)\n",
      "Epoch 1 Batch 0 Loss 4.5060 Accuracy0.0000\n",
      "(64, 37)\n",
      "(64, 37)\n",
      "(64, 34)\n",
      "(64, 34, 128)\n",
      "(1, 34, 128)\n",
      "(64, 37)\n",
      "(64, 37)\n",
      "(64, 37)\n",
      "(64, 37, 128)\n",
      "(1, 37, 128)\n",
      "(64, 36)\n",
      "(64, 36)\n",
      "(64, 36)\n",
      "(64, 36, 128)\n",
      "(1, 36, 128)\n",
      "(64, 39)\n",
      "(64, 39)\n",
      "(64, 36)\n",
      "(64, 36, 128)\n",
      "(1, 36, 128)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 37)\n",
      "(64, 37)\n",
      "(64, 36)\n",
      "(64, 36, 128)\n",
      "(1, 36, 128)\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 38)\n",
      "(64, 38)\n",
      "(64, 38)\n",
      "(64, 38, 128)\n",
      "(1, 38, 128)\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 7 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 39)\n",
      "(64, 39)\n",
      "(64, 38)\n",
      "(64, 38, 128)\n",
      "(1, 38, 128)\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 8 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 39)\n",
      "(64, 39)\n",
      "(64, 37)\n",
      "(64, 37, 128)\n",
      "(1, 37, 128)\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 9 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 37)\n",
      "(64, 37)\n",
      "(64, 35)\n",
      "(64, 35, 128)\n",
      "(1, 35, 128)\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 35)\n",
      "(64, 35)\n",
      "(64, 35)\n",
      "(64, 35, 128)\n",
      "(1, 35, 128)\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 11 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 36)\n",
      "(64, 36)\n",
      "(64, 34)\n",
      "(64, 34, 128)\n",
      "(1, 34, 128)\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 35)\n",
      "(64, 35)\n",
      "(64, 36)\n",
      "(64, 36, 128)\n",
      "(1, 36, 128)\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 37)\n",
      "(64, 37)\n",
      "(64, 33)\n",
      "(64, 33, 128)\n",
      "(1, 33, 128)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 38)\n",
      "(64, 38)\n",
      "(64, 37)\n",
      "(64, 37, 128)\n",
      "(1, 37, 128)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 38)\n",
      "(64, 38)\n",
      "(64, 34)\n",
      "(64, 34, 128)\n",
      "(1, 34, 128)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 39)\n",
      "(64, 39)\n",
      "(64, 33)\n",
      "(64, 33, 128)\n",
      "(1, 33, 128)\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 13 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 38)\n",
      "(64, 38)\n",
      "(64, 33)\n",
      "(64, 33, 128)\n",
      "(1, 33, 128)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 37)\n",
      "(64, 37)\n",
      "(64, 38)\n",
      "(64, 38, 128)\n",
      "(1, 38, 128)\n",
      "WARNING:tensorflow:7 out of the last 12 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 12 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 34)\n",
      "(64, 34)\n",
      "(64, 38)\n",
      "(64, 38, 128)\n",
      "(1, 38, 128)\n",
      "(64, 38)\n",
      "(64, 38)\n",
      "(64, 35)\n",
      "(64, 35, 128)\n",
      "(1, 35, 128)\n",
      "(64, 38)\n",
      "(64, 38)\n",
      "(64, 32)\n",
      "(64, 32, 128)\n",
      "(1, 32, 128)\n",
      "(64, 39)\n",
      "(64, 39)\n",
      "(64, 35)\n",
      "(64, 35, 128)\n",
      "(1, 35, 128)\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 18 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 34)\n",
      "(64, 34)\n",
      "(64, 31)\n",
      "(64, 31, 128)\n",
      "(1, 31, 128)\n",
      "(64, 33)\n",
      "(64, 33)\n",
      "(64, 36)\n",
      "(64, 36, 128)\n",
      "(1, 36, 128)\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function train_step at 0x7f88505f14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 33)\n",
      "(64, 33)\n",
      "(64, 34)\n",
      "(64, 34, 128)\n",
      "(1, 34, 128)\n",
      "(64, 35)\n",
      "(64, 35)\n",
      "(64, 34)\n",
      "(64, 34, 128)\n",
      "(1, 34, 128)\n",
      "(64, 35)\n",
      "(64, 35)\n",
      "(64, 38)\n",
      "(64, 38, 128)\n",
      "(1, 38, 128)\n",
      "(64, 38)\n",
      "(64, 38)\n",
      "(64, 36)\n",
      "(64, 36, 128)\n",
      "(1, 36, 128)\n",
      "(64, 39)\n",
      "(64, 39)\n",
      "(64, 34)\n",
      "(64, 34, 128)\n",
      "(1, 34, 128)\n",
      "(64, 36)\n",
      "(64, 36)\n",
      "(64, 37)\n",
      "(64, 37, 128)\n",
      "(1, 37, 128)\n",
      "(64, 34)\n",
      "(64, 34)\n",
      "(64, 36)\n",
      "(64, 36, 128)\n",
      "(1, 36, 128)\n",
      "(64, 36)\n",
      "(64, 36)\n",
      "(64, 35)\n",
      "(64, 35, 128)\n",
      "(1, 35, 128)\n",
      "(64, 35)\n",
      "(64, 35)\n",
      "(64, 33)\n",
      "(64, 33, 128)\n",
      "(1, 33, 128)\n",
      "Epoch 1 Batch 100 Loss 4.2298 Accuracy0.0000\n",
      "(64, 34)\n",
      "(64, 34)\n",
      "(64, 35)\n",
      "(64, 35, 128)\n",
      "(1, 35, 128)\n",
      "(64, 36)\n",
      "(64, 36)\n",
      "(64, 38)\n",
      "(64, 38, 128)\n",
      "(1, 38, 128)\n",
      "(64, 36)\n",
      "(64, 36)\n",
      "(64, 33)\n",
      "(64, 33, 128)\n",
      "(1, 33, 128)\n",
      "(64, 34)\n",
      "(64, 34)\n",
      "(64, 37)\n",
      "(64, 37, 128)\n",
      "(1, 37, 128)\n",
      "(64, 34)\n",
      "(64, 34)\n",
      "(64, 33)\n",
      "(64, 33, 128)\n",
      "(1, 33, 128)\n",
      "Epoch 1 Batch 200 Loss 4.1142 Accuracy0.0000\n",
      "(64, 35)\n",
      "(64, 35)\n",
      "(64, 31)\n",
      "(64, 31, 128)\n",
      "(1, 31, 128)\n",
      "(64, 37)\n",
      "(64, 37)\n",
      "(64, 32)\n",
      "(64, 32, 128)\n",
      "(1, 32, 128)\n",
      "(64, 35)\n",
      "(64, 35)\n",
      "(64, 37)\n",
      "(64, 37, 128)\n",
      "(1, 37, 128)\n",
      "(64, 34)\n",
      "(64, 34)\n",
      "(64, 30)\n",
      "(64, 30, 128)\n",
      "(1, 30, 128)\n",
      "Epoch 1 Batch 300 Loss 3.9602 Accuracy0.0000\n",
      "(64, 35)\n",
      "(64, 35)\n",
      "(64, 32)\n",
      "(64, 32, 128)\n",
      "(1, 32, 128)\n",
      "(64, 33)\n",
      "(64, 33)\n",
      "(64, 37)\n",
      "(64, 37, 128)\n",
      "(1, 37, 128)\n",
      "(64, 33)\n",
      "(64, 33)\n",
      "(64, 30)\n",
      "(64, 30, 128)\n",
      "(1, 30, 128)\n",
      "(64, 36)\n",
      "(64, 36)\n",
      "(64, 31)\n",
      "(64, 31, 128)\n",
      "(1, 31, 128)\n",
      "Epoch 1 Batch 400 Loss 3.7907 Accuracy0.0000\n",
      "(64, 34)\n",
      "(64, 34)\n",
      "(64, 32)\n",
      "(64, 32, 128)\n",
      "(1, 32, 128)\n",
      "(64, 36)\n",
      "(64, 36)\n",
      "(64, 30)\n",
      "(64, 30, 128)\n",
      "(1, 30, 128)\n",
      "(64, 36)\n",
      "(64, 36)\n",
      "(64, 32)\n",
      "(64, 32, 128)\n",
      "(1, 32, 128)\n",
      "Epoch 1 Batch 500 Loss 3.6390 Accuracy0.0000\n",
      "(64, 32)\n",
      "(64, 32)\n",
      "(64, 32)\n",
      "(64, 32, 128)\n",
      "(1, 32, 128)\n",
      "Epoch 1 Batch 600 Loss 3.5187 Accuracy0.0000\n",
      "(64, 36)\n",
      "(64, 36)\n",
      "(64, 29)\n",
      "(64, 29, 128)\n",
      "(1, 29, 128)\n",
      "(18, 37)\n",
      "(18, 37)\n",
      "(18, 33)\n",
      "(18, 33, 128)\n",
      "(1, 33, 128)\n",
      "Epoch1 Loss3.4149 Accuracy 0.0000\n",
      "Time take for 1 epoch: 1826.6428825855255 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.7630 Accuracy0.0000\n",
      "(64, 32)\n",
      "(64, 32)\n",
      "(64, 38)\n",
      "(64, 38, 128)\n",
      "(1, 38, 128)\n",
      "(64, 33)\n",
      "(64, 33)\n",
      "(64, 35)\n",
      "(64, 35, 128)\n",
      "(1, 35, 128)\n",
      "(64, 32)\n",
      "(64, 32)\n",
      "(64, 33)\n",
      "(64, 33, 128)\n",
      "(1, 33, 128)\n",
      "Epoch 2 Batch 100 Loss 2.6238 Accuracy0.0000\n",
      "(64, 35)\n",
      "(64, 35)\n",
      "(64, 30)\n",
      "(64, 30, 128)\n",
      "(1, 30, 128)\n",
      "(64, 39)\n",
      "(64, 39)\n",
      "(64, 32)\n",
      "(64, 32, 128)\n",
      "(1, 32, 128)\n",
      "Epoch 2 Batch 200 Loss 2.5808 Accuracy0.0000\n",
      "(64, 33)\n",
      "(64, 33)\n",
      "(64, 38)\n",
      "(64, 38, 128)\n",
      "(1, 38, 128)\n",
      "(64, 32)\n",
      "(64, 32)\n",
      "(64, 26)\n",
      "(64, 26, 128)\n",
      "(1, 26, 128)\n",
      "(64, 38)\n",
      "(64, 38)\n",
      "(64, 30)\n",
      "(64, 30, 128)\n",
      "(1, 30, 128)\n",
      "Epoch 2 Batch 300 Loss 2.5469 Accuracy0.0000\n",
      "(64, 32)\n",
      "(64, 32)\n",
      "(64, 37)\n",
      "(64, 37, 128)\n",
      "(1, 37, 128)\n",
      "(64, 32)\n",
      "(64, 32)\n",
      "(64, 35)\n",
      "(64, 35, 128)\n",
      "(1, 35, 128)\n",
      "Epoch 2 Batch 400 Loss 2.5019 Accuracy0.0000\n",
      "Epoch 2 Batch 500 Loss 2.4631 Accuracy0.0000\n",
      "Epoch 2 Batch 600 Loss 2.4356 Accuracy0.0000\n",
      "(18, 30)\n",
      "(18, 30)\n",
      "(18, 30)\n",
      "(18, 30, 128)\n",
      "(1, 30, 128)\n",
      "Epoch2 Loss2.4130 Accuracy 0.0000\n",
      "Time take for 1 epoch: 1236.5649857521057 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.2131 Accuracy0.0000\n",
      "(64, 33)\n",
      "(64, 33)\n",
      "(64, 32)\n",
      "(64, 32, 128)\n",
      "(1, 32, 128)\n",
      "Epoch 3 Batch 100 Loss 2.2204 Accuracy0.0000\n",
      "(64, 32)\n",
      "(64, 32)\n",
      "(64, 31)\n",
      "(64, 31, 128)\n",
      "(1, 31, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/zx/anaconda3/envs/tf2/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-133-fedf814bbc48>\", line 23, in <module>\n",
      "    train_step(inp, tar)\n",
      "  File \"/home/zx/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 568, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/home/zx/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 599, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"/home/zx/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2363, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"/home/zx/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1611, in _filtered_call\n",
      "    self.captured_inputs)\n",
      "  File \"/home/zx/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1692, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"/home/zx/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 545, in call\n",
      "    ctx=ctx)\n",
      "  File \"/home/zx/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 61, in quick_execute\n",
      "    num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zx/anaconda3/envs/tf2/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zx/anaconda3/envs/tf2/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/zx/anaconda3/envs/tf2/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/zx/anaconda3/envs/tf2/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/zx/anaconda3/envs/tf2/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/zx/anaconda3/envs/tf2/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/zx/anaconda3/envs/tf2/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/zx/anaconda3/envs/tf2/lib/python3.7/inspect.py\", line 732, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "train_loss = keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_out = tar[:, 1:]\n",
    "    encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask = create_masks(inp, tar_inp)\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred, _ = transformer(inp, tar_inp, True, encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask)\n",
    "        loss_ = loss_func(tar_out, pred)\n",
    "    gradients = tape.gradient(loss_, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "    train_loss(loss_)\n",
    "    \n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f} Accuracy{:.4f}'.format(epoch+1, batch, train_loss.result(), train_accuracy.result()))\n",
    "    print('Epoch{} Loss{:.4f} Accuracy {:.4f}'.format(epoch+1, train_loss.result(), train_accuracy.result()))\n",
    "    print('Time take for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
