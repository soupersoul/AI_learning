{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sys\n",
    "import time\n",
    "from tensorflow import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n"
     ]
    }
   ],
   "source": [
    "# https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
    "input_filepath = \"./shakespeare.txt\"\n",
    "text = open(input_filepath, 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56]\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "char2idx = { chr : idx for idx, chr in enumerate(vocab)}\n",
    "text_as_intarr = np.array([char2idx[c] for c in text])\n",
    "print(vocab)\n",
    "print(char2idx)\n",
    "print(text_as_intarr[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('abcd', 'bcde')\n"
     ]
    }
   ],
   "source": [
    "def split_input_target(text):\n",
    "    return (text[0:-1], text[1:])\n",
    "\n",
    "print(split_input_target('abcde'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[50 44  6 ... 47 56  6]\n",
      " [63  1 58 ... 50 43  7]\n",
      " [51  5 42 ... 58  1  5]\n",
      " ...\n",
      " [ 1 41 39 ... 53 57 57]\n",
      " [33 54 53 ... 56 53 54]\n",
      " [45 39 47 ... 39 49  6]], shape=(64, 100), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[44  6  1 ... 56  6  0]\n",
      " [ 1 58 56 ... 43  7 61]\n",
      " [ 5 42  1 ...  1  5 58]\n",
      " ...\n",
      " [41 39 52 ... 57 57  1]\n",
      " [54 53 52 ... 53 54 43]\n",
      " [39 47 52 ... 49  6  1]], shape=(64, 100), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[ 1 58 46 ...  0 18 56]\n",
      " [61 47 58 ... 50 42  5]\n",
      " [46 43  1 ... 53 56 57]\n",
      " ...\n",
      " [52 10  0 ... 13 51 43]\n",
      " [ 1 58 53 ... 52  1 43]\n",
      " [ 1 40 43 ... 61 39 56]], shape=(64, 100), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[58 46 53 ... 18 56 53]\n",
      " [47 58 46 ... 42  5 57]\n",
      " [43  1 51 ... 56 57  5]\n",
      " ...\n",
      " [10  0 20 ... 51 43 52]\n",
      " [58 53  1 ...  1 43 50]\n",
      " [40 43 43 ... 39 56 42]], shape=(64, 100), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_intarr)\n",
    "seq_length = 100\n",
    "seq_dataset = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "batch_size = 64\n",
    "shuffle_size = 10000\n",
    "seq_dataset = seq_dataset.map(split_input_target)\n",
    "seq_dataset = seq_dataset.shuffle(shuffle_size).batch(batch_size, drop_remainder=True)\n",
    "for (d1, d2) in seq_dataset.take(2):\n",
    "    print(d1)\n",
    "    print(d2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "embedding_dim=256\n",
    "rnn_units=1024\n",
    "# 用embedding_dim = 128，rnn_units=512试过，效果极差 \n",
    "vocab_size = len(vocab)\n",
    "def build_model(vocab_size, embedding_size, rnn_units, batch_size):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Embedding(vocab_size, embedding_size, batch_input_shape=[batch_size, None]),\n",
    "        keras.layers.LSTM(units=rnn_units, stateful=True, recurrent_initializer=\"glorot_normal\", return_sequences=True),\n",
    "        keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
    "\n",
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65)\n",
      "tf.Tensor(\n",
      "[[10]\n",
      " [35]\n",
      " [26]\n",
      " [28]\n",
      " [34]\n",
      " [49]\n",
      " [42]\n",
      " [62]\n",
      " [ 9]\n",
      " [28]\n",
      " [38]\n",
      " [33]\n",
      " [ 3]\n",
      " [21]\n",
      " [40]\n",
      " [45]\n",
      " [23]\n",
      " [38]\n",
      " [52]\n",
      " [20]\n",
      " [10]\n",
      " [14]\n",
      " [26]\n",
      " [55]\n",
      " [64]\n",
      " [ 3]\n",
      " [23]\n",
      " [24]\n",
      " [22]\n",
      " [23]\n",
      " [43]\n",
      " [16]\n",
      " [19]\n",
      " [15]\n",
      " [40]\n",
      " [17]\n",
      " [46]\n",
      " [ 9]\n",
      " [60]\n",
      " [10]\n",
      " [ 2]\n",
      " [15]\n",
      " [ 7]\n",
      " [40]\n",
      " [ 2]\n",
      " [23]\n",
      " [16]\n",
      " [44]\n",
      " [47]\n",
      " [17]\n",
      " [33]\n",
      " [ 6]\n",
      " [62]\n",
      " [10]\n",
      " [35]\n",
      " [43]\n",
      " [53]\n",
      " [56]\n",
      " [13]\n",
      " [ 8]\n",
      " [42]\n",
      " [54]\n",
      " [20]\n",
      " [17]\n",
      " [49]\n",
      " [35]\n",
      " [43]\n",
      " [16]\n",
      " [ 7]\n",
      " [13]\n",
      " [30]\n",
      " [50]\n",
      " [10]\n",
      " [36]\n",
      " [64]\n",
      " [53]\n",
      " [41]\n",
      " [30]\n",
      " [45]\n",
      " [20]\n",
      " [58]\n",
      " [44]\n",
      " [40]\n",
      " [ 0]\n",
      " [ 4]\n",
      " [30]\n",
      " [48]\n",
      " [ 7]\n",
      " [60]\n",
      " [20]\n",
      " [16]\n",
      " [15]\n",
      " [42]\n",
      " [52]\n",
      " [ 7]\n",
      " [48]\n",
      " [40]\n",
      " [36]\n",
      " [59]\n",
      " [14]], shape=(100, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[10 35 26 28 34 49 42 62  9 28 38 33  3 21 40 45 23 38 52 20 10 14 26 55\n",
      " 64  3 23 24 22 23 43 16 19 15 40 17 46  9 60 10  2 15  7 40  2 23 16 44\n",
      " 47 17 33  6 62 10 35 43 53 56 13  8 42 54 20 17 49 35 43 16  7 13 30 50\n",
      " 10 36 64 53 41 30 45 20 58 44 40  0  4 30 48  7 60 20 16 15 42 52  7 48\n",
      " 40 36 59 14], shape=(100,), dtype=int64)\n",
      "Input:  \"e   m e r r y   o n e s . \\n \\n A U T O L Y C U S : \\n W h y ,   t h i s   i s   a   p a s s i n g   m e r r y   o n e   a n d   g o e s   t o \\n t h e   t u n e   o f   ' T w o   m a i d s   w o o i n g\"\n",
      "\n",
      "Output:  \"  m e r r y   o n e s . \\n \\n A U T O L Y C U S : \\n W h y ,   t h i s   i s   a   p a s s i n g   m e r r y   o n e   a n d   g o e s   t o \\n t h e   t u n e   o f   ' T w o   m a i d s   w o o i n g  \"\n",
      "\n",
      "Predictions:  ': W N P V k d x 3 P Z U $ I b g K Z n H : B N q z $ K L J K e D G C b E h 3 v : ! C - b ! K D f i E U , x : W e o r A . d p H E k W e D - A R l : X z o c R g H t f b \\n & R j - v H D C d n - j b X u B'\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in seq_dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape)\n",
    "\n",
    "# randomm sampling\n",
    "# greedy, random\n",
    "sample_indices = tf.random.categorical(logits = example_batch_predictions[0], num_samples = 1)\n",
    "print(sample_indices)\n",
    "\n",
    "sample_indices = tf.squeeze(sample_indices, axis = -1)\n",
    "print(sample_indices)\n",
    "\n",
    "print(\"Input: \", repr(\" \".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Output: \", repr(\" \".join(idx2char[target_example_batch[0]])))\n",
    "print()\n",
    "print(\"Predictions: \", repr(\" \".join(idx2char[sample_indices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    # 模型里最后一层没有softmax，所以返回的是logits，而不是概率分布，所以from_logits＝True\n",
    "    return keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits = True)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 172 steps\n",
      "Epoch 1/20\n",
      "172/172 [==============================] - 525s 3s/step - loss: 2.6290\n",
      "Epoch 2/20\n",
      "172/172 [==============================] - 514s 3s/step - loss: 1.9201\n",
      "Epoch 3/20\n",
      "172/172 [==============================] - 515s 3s/step - loss: 1.6633\n",
      "Epoch 4/20\n",
      "172/172 [==============================] - 512s 3s/step - loss: 1.5219\n",
      "Epoch 5/20\n",
      "172/172 [==============================] - 513s 3s/step - loss: 1.4381\n",
      "Epoch 6/20\n",
      "172/172 [==============================] - 514s 3s/step - loss: 1.3793\n",
      "Epoch 7/20\n",
      "172/172 [==============================] - 518s 3s/step - loss: 1.3342\n",
      "Epoch 8/20\n",
      "172/172 [==============================] - 537s 3s/step - loss: 1.2957\n",
      "Epoch 9/20\n",
      "172/172 [==============================] - 622s 4s/step - loss: 1.2600\n",
      "Epoch 10/20\n",
      "172/172 [==============================] - 736s 4s/step - loss: 1.2257\n",
      "Epoch 11/20\n",
      "172/172 [==============================] - 579s 3s/step - loss: 1.1909\n",
      "Epoch 12/20\n",
      "172/172 [==============================] - 517s 3s/step - loss: 1.1567\n",
      "Epoch 13/20\n",
      "172/172 [==============================] - 571s 3s/step - loss: 1.1189\n",
      "Epoch 14/20\n",
      "172/172 [==============================] - 607s 4s/step - loss: 1.0820\n",
      "Epoch 15/20\n",
      "172/172 [==============================] - 515s 3s/step - loss: 1.0433\n",
      "Epoch 16/20\n",
      "172/172 [==============================] - 511s 3s/step - loss: 1.0028\n",
      "Epoch 17/20\n",
      "172/172 [==============================] - 512s 3s/step - loss: 0.9611\n",
      "Epoch 18/20\n",
      "172/172 [==============================] - 512s 3s/step - loss: 0.9200\n",
      "Epoch 19/20\n",
      "172/172 [==============================] - 512s 3s/step - loss: 0.8801\n",
      "Epoch 20/20\n",
      "172/172 [==============================] - 511s 3s/step - loss: 0.8399\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"./text_generation_checkpoints\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "checkpoint_prefix = os.path.join(output_dir, 'ckpt_{epoch}')\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_prefix,\n",
    "    save_weights_only = True\n",
    ")\n",
    "epochs = 20\n",
    "history = model.fit(seq_dataset, epochs = epochs, callbacks = [checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "applied_model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "applied_model.load_weights(tf.train.latest_checkpoint(output_dir))\n",
    "applied_model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I shall entreat me speak.\n",
      "\n",
      "CLIFFORD:\n",
      "How must he does not presently the people\n",
      "Your providest heart my penitent that be made.\n",
      "\n",
      "GLOUCESTER:\n",
      "What is thy name?\n",
      "\n",
      "CORIOLANUS:\n",
      "The king shall meet thee, thou shalt still have\n",
      "Our torts of stone, that we may be meet,\n",
      "And therefore I'll not be so valiant husband.\n",
      "A grave beloved, that thought there was my wanton piece of spirits than a present and sheep-worthy love.\n",
      "\n",
      "VINCENTIO:\n",
      "As if that news, my lord.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "I know him for this business.\n",
      "\n",
      "AUFI\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_text, gen_text_num):\n",
    "    input_eval = [char2idx[c] for c in start_text]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    text_generated = []\n",
    "    model.reset_states()\n",
    "    \n",
    "    # temperature > 1, random\n",
    "    # temperature > 1, greedy\n",
    "    temperature = 0.5\n",
    "\n",
    "    for _ in range(gen_text_num):\n",
    "        predict = model(input_eval)\n",
    "        predict = predict / temperature\n",
    "        \n",
    "        predict = tf.squeeze(predict, 0)\n",
    "        # random比greedy更适用，random是按softmax的概率来输出，即a:0.8, b:0.15, c:0.05，则80%得到的结果是a, 而greedy则只可能是a\n",
    "        predict_id = tf.random.categorical(predict, num_samples=1)[-1, 0].numpy()\n",
    "        predict_char = idx2char[predict_id]\n",
    "        text_generated.append(predict_char)\n",
    "        input_eval = tf.expand_dims([predict_id], 0) # lstmk只需要刚预测出来的值\n",
    "    return \"\".join(text_generated)\n",
    "\n",
    "test = generate_text(applied_model, \"All: \", 500)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
