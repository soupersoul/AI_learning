{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627\n",
      "264\n",
      "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1         1  female  38.0                   1      0  71.2833  First        C   \n",
      "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3         1  female  35.0                   1      0  53.1000  First        C   \n",
      "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n"
     ]
    }
   ],
   "source": [
    "#https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
    "#https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
    "train_file = \"./data/train.csv\"\n",
    "eval_file = \"./data/eval.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "print(len(train_df))\n",
    "print(len(eval_df))\n",
    "print(train_df.head())  # head() 默认取前５条数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df.pop('survived')\n",
    "y_eval = eval_df.pop('survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck', 'embark_town', 'alone']\n",
    "numeric_columns = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "for cc in categorical_columns:\n",
    "    vocab = train_df[cc].unique()\n",
    "    print(cc, vocab)\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.indicator_column( # indicator_column: can do one hot\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                cc, vocab\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "for cc in numeric_columns:\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(\n",
    "            cc, dtype=tf.float32\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_df, label_df, epochs = 10, shuffle=True, batch_size =32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dict(data_df), label_df)\n",
    "    )\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'os' has no attribute 'make_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d881f591dd6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./customized_estimator\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'os' has no attribute 'make_dir'"
     ]
    }
   ],
   "source": [
    "output_dir = \"./customized_estimator\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    # mode: model runtime state : Train, Eval, Predict\n",
    "    input_for_next_layer = tf.feature_column.input_layer(\n",
    "        features, params['feature_columns']\n",
    "    )\n",
    "    for n_unit in params['hidden_units']:\n",
    "        input_for_next_layer = tf.layers.dense(\n",
    "            input_for_next_layer,\n",
    "            units = n_unit,\n",
    "            activation = tf.nn.relu\n",
    "        )\n",
    "    logits = tf.layers.dense(input_for_next_layer,\n",
    "                            params['n_classes'],\n",
    "                            activation=None)\n",
    "    predicted_classes = tf.argmax(logits, 1)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            \"class_ids\": predicted_classes[:, tf.newaxis],\n",
    "            \"probabilities\": tf.nn.softmax(logits),\n",
    "            \"logits\": logits\n",
    "            \n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions = predictions)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels = labels, logits = logits)\n",
    "    accuracy = tf.metrics.accuracy(labels = labels,\n",
    "                                  predictions  = predicted_classes,\n",
    "                                  name = \"acc_op\")\n",
    "    metrics = {\"accuracy\": accuracy}\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops = metrics)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train_op = optimizer.minize(loss, global_step=tf.train.get_global_step())\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op = train_op)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn = model_fn,\n",
    "    model_dir = output_dir,\n",
    "    params = {\n",
    "        \"feature_columns\": feature_columns,\n",
    "        \"hidden_units\": [30, 50],\n",
    "        \"n_classes\": 2\n",
    "    }\n",
    ")\n",
    "\n",
    "estimator.train(input_fn = lambda : make_dataset(\n",
    "    train_df, y_train, epochs = 100\n",
    "  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.evaluate(lambda: make_dataset(eval_df, y_eval, epochs=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
